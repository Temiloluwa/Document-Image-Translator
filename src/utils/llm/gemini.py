from ._base import LLM
from google import genai
from google.genai.types import GenerateContentConfig, GenerateContentResponse
from models.message import GeminiUserMessage, GeminiAssistantMessage
from PIL import Image
from typing import List, Dict, Any
import os


class Gemini(LLM):
    """
    A class representing the Gemini LLM (Large Language Model) interface.

    This class provides methods to set up and interact with the Gemini LLM for generating content
    based on text prompts and images.
    """

    def __init__(self, system_instruction: str, **kwargs: Dict[str, Any]) -> None:
        """
        Initialize the Gemini LLM with a system instruction and optional configuration parameters.

        Args:
            system_instruction (str): The system instruction to guide the LLM's behavior.
            **kwargs: Additional configuration parameters for the LLM.
        """
        self._setup(system_instruction, **kwargs)

    def _setup(self, system_instruction: str, **kwargs: Dict[str, Any]) -> None:  # type: ignore[override]
        """
        Set up the Gemini LLM client and configuration.

        Args:
            system_instruction (str): The system instruction to guide the LLM's behavior.
            **kwargs: Additional configuration parameters for the LLM.
        """
        self._config = GenerateContentConfig(
            system_instruction=system_instruction,
            **kwargs,  # type: ignore[arg-type]
        )
        self._client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

    def generate(  # type: ignore[override]
        self, prompt: str, images: List[Image.Image]
    ) -> GeminiAssistantMessage:
        """
        Generate a response from the Gemini LLM based on a text prompt and an image.

        Args:
            prompt (str): The text prompt to guide the LLM's response.
            images (List[Image.Image]): A list of images to provide additional context for the LLM.

        Returns:
            GeminiAssistantMessage: The response generated by the Gemini LLM.
        """
        prompt = prompt.replace("\n", " ").strip()

        response = self._client.models.generate_content(
            model=os.getenv("LLM"),  # type: ignore[arg-type]
            contents=GeminiUserMessage(prompt, images).contents,  # type: ignore[arg-type]
            config=self._config,
        )

        return self._parse_output(response)

    def _parse_output(  # type: ignore[override]
        self, response: GenerateContentResponse
    ) -> GeminiAssistantMessage:
        return GeminiAssistantMessage(response)
